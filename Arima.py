# -*- coding: utf-8 -*-
"""
Created on Sun May 22 21:23:20 2022

@author: shikhar
"""

import numpy as np
import matplotlib as plt
import pandas as pd
import matplotlib.pyplot as plt # Import matplotlib for data visualisation
import seaborn as sns # Statistical data visualization
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

from statsmodels.tsa.ar_model import AR
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller, kpss, ccf
import statsmodels.api as sm

def plot_series(df=None, column=None, series=pd.Series([]), 
                label=None, ylabel=None, title=None, start=0, end=None):
    """
    Plots a certain time-series which has either been loaded in a dataframe
    and which constitutes one of its columns or it a custom pandas series 
    created by the user. The user can define either the 'df' and the 'column' 
    or the 'series' and additionally, can also define the 'label', the 
    'ylabel', the 'title', the 'start' and the 'end' of the plot.
    """
    sns.set()
    fig, ax = plt.subplots(figsize=(30, 12))
    ax.set_xlabel('Time', fontsize=16)
    if column:
        ax.plot(df[column][start:end], label=label)
        ax.set_ylabel(ylabel, fontsize=16)
    if series.any():
        ax.plot(series, label=label)
        ax.set_ylabel(ylabel, fontsize=16)
    if label:
        ax.legend(fontsize=16)
    if title:
        ax.set_title(title, fontsize=24)
    ax.grid(True)
    return ax

df=pd.read_csv('PJMs.csv',sep=";")

df.set_index('Date', inplace=True)

dataset = df[(df >= 0).all(1)]



rolling = dataset['PJM'].rolling(24*7, center=True).mean()
ax = plot_series(dataset, 'PJM', label='Hourly', ylabel='Actual Price (â‚¬/MWh)',
                 title='Actual Hourly Electricity Price and Weekly rolling mean')
ax.plot(rolling, linestyle='-', linewidth=2, label='Weekly rolling mean')
plt.show()


ax = dataset['PJM'].plot.hist(bins=18, alpha=0.65)

res = sm.tsa.seasonal_decompose(df['PJM'], freq=24)

fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 12))
res.observed.plot(ax=ax1, title='Observed')
res.trend.plot(ax=ax2, title='Trend')
res.resid.plot(ax=ax3, title='Residual')
res.seasonal.plot(ax=ax4, title='Seasonal')
plt.tight_layout()
plt.show()

y = dataset['PJM']
adf_test = adfuller(y, regression='c')
print('ADF Statistic: {:.6f}\np-value: {:.6f}\n#Lags used: {}'
      .format(adf_test[0], adf_test[1], adf_test[2]))
for key, value in adf_test[4].items():
    print('Critical Value ({}): {:.6f}'.format(key, value))


kpss_test = kpss(y, regression='c', lags='legacy')
print('KPSS Statistic: {:.6f}\np-value: {:.6f}\n#Lags used: {}'
      .format(kpss_test[0], kpss_test[1], kpss_test[2]))
for key, value in kpss_test[3].items():
    print('Critical Value ({}): {:.6f}'.format(key, value))
    
fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))
plot_acf(df_final['price actual'], lags=50, ax=ax1)
plot_pacf(df_final['price actual'], lags=50, ax=ax2)
plt.tight_layout()
plt.show()

fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))
plot_acf(dataset['PJM'], lags=50, ax=ax1)
plot_pacf(dataset['PJM'], lags=50, ax=ax2)
plt.tight_layout()
plt.show()

train, test = dataset.iloc[:int(len(dataset)*0.8),0].values, dataset.iloc[int(len(dataset)*0.8):,0].values


import statsmodels.api as sm


model = sm.tsa.arima.ARIMA(train, order=(4,0,0))

model_fit = model.fit()

test_predict = model_fit.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# invert predictions
scaler.fit(test_predict.reshape(-1, 1))
test_predict = scaler.inverse_transform(test_predict.reshape(-1, 1))

scaler.fit(test.reshape(-1, 1))
Y_test = scaler.inverse_transform(test.reshape(-1, 1))
print('Test Mean Absolute Error:', mean_absolute_error(Y_test, test_predict))
print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test, test_predict)))


aa=[i for i in range(len(test))]
plt.plot(aa,test, 'g', label="data-driven", linewidth=4)
plt.plot(aa,test_predict ,'k', label="PINN", linewidth=4)















def create_dataset(dataset, look_back):
    X, Y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)


look_back = 1





X_train, Y_train = create_dataset(train[:,None], look_back)
X_test, Y_test = create_dataset(test[:,None], look_back)

# reshape input to be [samples, time steps, features]
X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))

model = Sequential()
model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2])))
#model.add(Dropout(0.2))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

history = model.fit(X_train, Y_train, epochs=100, batch_size=70, validation_data=(X_test, Y_test),verbose=1, shuffle=False)

model.summary()

train_predict = model.predict(X_train)
test_predict = model.predict(X_test)


print('Train Mean Absolute Error:', mean_absolute_error(Y_train[0], train_predict[:,0]))
print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0])))
print('Test Mean Absolute Error:', mean_absolute_error(Y_test[0], test_predict[:,0]))
print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test[0], test_predict[:,0])))

plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.title('model loss')

idx = len(Y_test)
aa=[x for x in range(len(Y_test))]
plt.figure(figsize=(8,4))
plt.plot(aa, Y_test[:idx], marker='.', label="actual")
plt.plot(aa, test_predict[:idx,0], 'r', label="prediction")


np.savetxt('test_predict.csv', test_predict)



"""